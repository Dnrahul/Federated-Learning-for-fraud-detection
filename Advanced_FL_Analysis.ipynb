{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57663c3f",
   "metadata": {},
   "source": [
    "# Advanced Federated Learning for Cross-Bank Fraud Detection\n",
    "\n",
    "## With Differential Privacy, FedDANE, and Privacy Auditing\n",
    "\n",
    "This notebook demonstrates an enhanced federated learning framework with:\n",
    "- **FedAvg**: Standard federated averaging\n",
    "- **FedProx**: Improved optimization with proximal regularization\n",
    "- **FedDANE**: Variance-reduced aggregation (NEW)\n",
    "- **Differential Privacy (DP-SGD)**: Privacy-preserving training (NEW)\n",
    "- **Privacy Auditing**: Membership inference attacks and privacy metrics (NEW)\n",
    "- **Heterogeneity Simulation**: Non-IID data and client dropout (NEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af32d1",
   "metadata": {},
   "source": [
    "## Step 1: Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16886d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['torch', 'pandas', 'scikit-learn', 'numpy', 'matplotlib', 'seaborn']\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "\n",
    "print('‚úÖ All packages installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from federated_learning.models import FraudDetectionModel, FraudDetectionModelEnhanced\n",
    "from federated_learning.privacy import DifferentialPrivacyEngine, MembershipInferenceAttack\n",
    "from federated_learning.aggregators import FedAvgAggregator, FedProxAggregator, FedDANEAggregator\n",
    "from federated_learning.utils import DataPreprocessor\n",
    "from federated_learning.utils.training import ClientTrainer, ModelEvaluator, TrainingMetricsTracker\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'üñ•Ô∏è Using device: {device}')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1e569f",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8458e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data paths\n",
    "data_dir = '../Data'\n",
    "csv_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "\n",
    "print(f'üìÅ Found {len(csv_files)} CSV files:')\n",
    "for f in csv_files:\n",
    "    print(f'  - {os.path.basename(f)}')\n",
    "\n",
    "# Load and preprocess data\n",
    "preprocessor = DataPreprocessor()\n",
    "client_data, input_dim = preprocessor.load_and_preprocess_csvs(\n",
    "    csv_files,\n",
    "    label_column='Is_Fraud',\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f'\\n‚úÖ Data loaded and preprocessed')\n",
    "print(f'üìä Number of clients: {len(client_data)}')\n",
    "print(f'üî¢ Input feature dimension: {input_dim}')\n",
    "print(f'üìã Feature names: {list(preprocessor.feature_names)}')\n",
    "\n",
    "# Print data distribution\n",
    "for i, (train_df, test_df) in enumerate(client_data, 1):\n",
    "    fraud_rate = train_df['Is_Fraud'].mean()\n",
    "    print(f'\\nClient {i}: Train={len(train_df)}, Test={len(test_df)}, Fraud Rate={fraud_rate:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda8868b",
   "metadata": {},
   "source": [
    "## Step 3: Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for each client\n",
    "batch_size = 32\n",
    "client_train_loaders = []\n",
    "client_test_loaders = []\n",
    "\n",
    "for i, (train_df, test_df) in enumerate(client_data):\n",
    "    train_loader, test_loader = preprocessor.create_dataloaders(\n",
    "        train_df, test_df,\n",
    "        label_column='Is_Fraud',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    client_train_loaders.append(train_loader)\n",
    "    client_test_loaders.append(test_loader)\n",
    "\n",
    "print(f'‚úÖ Created {len(client_train_loaders)} train and test loaders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1389d6",
   "metadata": {},
   "source": [
    "## Step 4: Compare Federated Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for federated learning\n",
    "num_rounds = 5\n",
    "local_epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "algorithms = {\n",
    "    'FedAvg': {'aggregator': FedAvgAggregator(), 'mu': 0.0},\n",
    "    'FedProx (Œº=0.01)': {'aggregator': FedProxAggregator(mu=0.01), 'mu': 0.01},\n",
    "    'FedDANE': {'aggregator': FedDANEAggregator(learning_rate=0.01), 'mu': 0.0},\n",
    "}\n",
    "\n",
    "results = {}\n",
    "evaluator = ModelEvaluator(device=device)\n",
    "\n",
    "for alg_name, alg_config in algorithms.items():\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'üöÄ Training with {alg_name}')\n",
    "    print(f'{\"=\"*60}')\n",
    "    \n",
    "    aggregator = alg_config['aggregator']\n",
    "    mu = alg_config['mu']\n",
    "    \n",
    "    # Initialize global model\n",
    "    global_model = FraudDetectionModel(input_dim).to(device)\n",
    "    trainer = ClientTrainer(model=None, device=device, learning_rate=learning_rate)\n",
    "    \n",
    "    client_accuracies = {i: [] for i in range(len(client_data))}\n",
    "    round_accuracies = []\n",
    "    \n",
    "    # Federated training rounds\n",
    "    for round_num in range(num_rounds):\n",
    "        print(f'\\nüîÅ Round {round_num + 1}/{num_rounds}')\n",
    "        \n",
    "        client_models = []\n",
    "        \n",
    "        # Local training on each client\n",
    "        for client_id, train_loader in enumerate(client_train_loaders):\n",
    "            # Create client model with global weights\n",
    "            client_model = FraudDetectionModel(input_dim).to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            \n",
    "            # Train client\n",
    "            trainer.model = client_model\n",
    "            train_metrics = trainer.train_one_round(\n",
    "                train_loader,\n",
    "                epochs=local_epochs,\n",
    "                global_model=global_model if mu > 0 else None,\n",
    "                mu=mu\n",
    "            )\n",
    "            \n",
    "            client_models.append(client_model)\n",
    "        \n",
    "        # Server aggregation\n",
    "        if isinstance(aggregator, FedDANEAggregator):\n",
    "            aggregator.aggregate(client_models, global_model, client_updates=None)\n",
    "        else:\n",
    "            aggregator.aggregate(client_models, global_model)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        round_acc = []\n",
    "        for client_id, test_loader in enumerate(client_test_loaders):\n",
    "            metrics = evaluator.evaluate(global_model, test_loader, label=f'Client {client_id+1} (Round {round_num+1})')\n",
    "            acc = metrics['accuracy']\n",
    "            client_accuracies[client_id].append(acc)\n",
    "            round_acc.append(acc)\n",
    "        \n",
    "        avg_round_acc = np.mean(round_acc)\n",
    "        round_accuracies.append(avg_round_acc)\n",
    "        print(f'üìà Average accuracy: {avg_round_acc:.4f}')\n",
    "    \n",
    "    results[alg_name] = {\n",
    "        'client_accuracies': client_accuracies,\n",
    "        'round_accuracies': round_accuracies,\n",
    "        'final_accuracies': [accs[-1] for accs in client_accuracies.values()]\n",
    "    }\n",
    "\n",
    "print(f'\\n‚úÖ All algorithms trained successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f56b2",
   "metadata": {},
   "source": [
    "## Step 5: Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8628a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "print(f'\\n{\"=\"*70}')\n",
    "print('üìä FINAL ACCURACY COMPARISON TABLE')\n",
    "print(f'{\"=\"*70}')\n",
    "\n",
    "comparison_df = pd.DataFrame()\n",
    "for alg_name, result in results.items():\n",
    "    comparison_df[alg_name] = result['final_accuracies']\n",
    "\n",
    "comparison_df.index = [f'Client {i+1}' for i in range(len(client_data))]\n",
    "print(comparison_df.to_string())\n",
    "print(f'\\nAverage: {comparison_df.mean().to_dict()}')\n",
    "print(f'{\"=\"*70}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ac8bf",
   "metadata": {},
   "source": [
    "## Step 6: Convergence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30eae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence curves\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for i, (alg_name, result) in enumerate(results.items()):\n",
    "    rounds = list(range(1, num_rounds + 1))\n",
    "    plt.plot(rounds, result['round_accuracies'], marker='o', label=alg_name, linewidth=2, markersize=8)\n",
    "\n",
    "plt.xlabel('Communication Round', fontsize=12)\n",
    "plt.ylabel('Average Accuracy', fontsize=12)\n",
    "plt.title('Federated Learning Algorithm Convergence Comparison', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Convergence plot generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb5f50f",
   "metadata": {},
   "source": [
    "## Step 7: Differential Privacy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print('üîê DIFFERENTIAL PRIVACY FEDERATED LEARNING')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "# DP Configuration\n",
    "dp_configs = {\n",
    "    'No Privacy': {'noise_multiplier': 0.0, 'max_grad_norm': 1.0},\n",
    "    'DP-SGD (œÉ=0.5)': {'noise_multiplier': 0.5, 'max_grad_norm': 1.0},\n",
    "    'DP-SGD (œÉ=1.0)': {'noise_multiplier': 1.0, 'max_grad_norm': 1.0},\n",
    "}\n",
    "\n",
    "dp_results = {}\n",
    "\n",
    "for dp_name, dp_config in dp_configs.items():\n",
    "    print(f'\\nüöÄ Training with {dp_name}')\n",
    "    print(f'  Noise Multiplier: {dp_config[\"noise_multiplier\"]}')\n",
    "    \n",
    "    # Initialize privacy engine\n",
    "    privacy_engine = DifferentialPrivacyEngine(\n",
    "        noise_multiplier=dp_config['noise_multiplier'],\n",
    "        max_grad_norm=dp_config['max_grad_norm'],\n",
    "        delta=1e-5\n",
    "    )\n",
    "    \n",
    "    # Initialize global model\n",
    "    global_model = FraudDetectionModel(input_dim).to(device)\n",
    "    trainer = ClientTrainer(model=None, device=device, learning_rate=learning_rate)\n",
    "    aggregator = FedAvgAggregator()\n",
    "    \n",
    "    round_accuracies = []\n",
    "    privacy_budgets = []\n",
    "    \n",
    "    # Federated training with DP\n",
    "    for round_num in range(num_rounds):\n",
    "        client_models = []\n",
    "        \n",
    "        for train_loader in client_train_loaders:\n",
    "            client_model = FraudDetectionModel(input_dim).to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            \n",
    "            trainer.model = client_model\n",
    "            trainer.train_one_round(\n",
    "                train_loader,\n",
    "                epochs=local_epochs,\n",
    "                use_dp=True,\n",
    "                dp_engine=privacy_engine\n",
    "            )\n",
    "            \n",
    "            client_models.append(client_model)\n",
    "        \n",
    "        aggregator.aggregate(client_models, global_model)\n",
    "        \n",
    "        # Evaluate\n",
    "        accs = []\n",
    "        for test_loader in client_test_loaders:\n",
    "            metrics = evaluator.evaluate(global_model, test_loader, label=f'DP-{dp_name} Round {round_num+1}')\n",
    "            accs.append(metrics['accuracy'])\n",
    "        \n",
    "        avg_acc = np.mean(accs)\n",
    "        round_accuracies.append(avg_acc)\n",
    "        \n",
    "        # Compute privacy loss\n",
    "        total_samples = sum(len(loader.dataset) for loader in client_train_loaders)\n",
    "        epsilon, delta = privacy_engine.compute_privacy_loss_basic(\n",
    "            total_samples, batch_size, round_num + 1\n",
    "        )\n",
    "        privacy_budgets.append((epsilon, delta))\n",
    "        \n",
    "        print(f'  Round {round_num + 1}: Acc={avg_acc:.4f}, Œµ={epsilon:.4f}, Œ¥={delta}')\n",
    "    \n",
    "    dp_results[dp_name] = {\n",
    "        'accuracies': round_accuracies,\n",
    "        'privacy_budgets': privacy_budgets\n",
    "    }\n",
    "\n",
    "print(f'\\n‚úÖ Differential Privacy training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1b550",
   "metadata": {},
   "source": [
    "## Step 8: Privacy-Utility Trade-off Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot privacy-utility trade-off\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Extract epsilon and accuracy for each configuration\n",
    "epsilons_by_config = {}\n",
    "accuracies_by_config = {}\n",
    "\n",
    "for dp_name, result in dp_results.items():\n",
    "    epsilons = [budget[0] for budget in result['privacy_budgets']]\n",
    "    accuracies = result['accuracies']\n",
    "    epsilons_by_config[dp_name] = epsilons\n",
    "    accuracies_by_config[dp_name] = accuracies\n",
    "\n",
    "# Plot 1: Accuracy over rounds\n",
    "plt.subplot(1, 2, 1)\n",
    "for dp_name, accs in accuracies_by_config.items():\n",
    "    plt.plot(range(1, num_rounds + 1), accs, marker='o', label=dp_name, linewidth=2)\n",
    "plt.xlabel('Round', fontsize=11)\n",
    "plt.ylabel('Accuracy', fontsize=11)\n",
    "plt.title('Model Accuracy with Different Privacy Levels', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Privacy-Utility Trade-off\n",
    "plt.subplot(1, 2, 2)\n",
    "for dp_name in dp_results.keys():\n",
    "    eps = epsilons_by_config[dp_name]\n",
    "    accs = accuracies_by_config[dp_name]\n",
    "    plt.plot(eps, accs, marker='s', label=dp_name, linewidth=2, markersize=7)\n",
    "plt.xlabel('Privacy Budget (Œµ)', fontsize=11)\n",
    "plt.ylabel('Accuracy', fontsize=11)\n",
    "plt.title('Privacy-Utility Trade-off', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Privacy-Utility trade-off plot generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769bf3b4",
   "metadata": {},
   "source": [
    "## Step 9: Non-IID Data Distribution and Heterogeneity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print('üìä NON-IID DATA HETEROGENEITY SIMULATION')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "# Combine all data for non-IID split\n",
    "all_train_data = pd.concat([train_df for train_df, _ in client_data], ignore_index=True)\n",
    "\n",
    "# Create non-IID distributions\n",
    "iid_degrees = [1.0, 0.5, 0.1]  # 1.0 = IID, 0.0 = fully non-IID\n",
    "heterogeneity_results = {}\n",
    "\n",
    "for iid_degree in iid_degrees:\n",
    "    print(f'\\nüöÄ Training with IID Degree = {iid_degree}')\n",
    "    \n",
    "    # Create non-IID splits\n",
    "    non_iid_clients = preprocessor.create_non_iid_data_split(\n",
    "        all_train_data,\n",
    "        num_clients=len(client_data),\n",
    "        iid_degree=iid_degree,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Create loaders for non-IID data\n",
    "    non_iid_train_loaders = []\n",
    "    non_iid_test_loaders = []\n",
    "    \n",
    "    for client_df in non_iid_clients:\n",
    "        if len(client_df) > 0:\n",
    "            train_df = client_df.sample(frac=0.8, random_state=42)\n",
    "            test_df = client_df.drop(train_df.index)\n",
    "            \n",
    "            train_loader, test_loader = preprocessor.create_dataloaders(\n",
    "                train_df, test_df,\n",
    "                label_column='Is_Fraud',\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            non_iid_train_loaders.append(train_loader)\n",
    "            non_iid_test_loaders.append(test_loader)\n",
    "    \n",
    "    # Train with FedAvg on non-IID data\n",
    "    global_model = FraudDetectionModel(input_dim).to(device)\n",
    "    trainer = ClientTrainer(model=None, device=device, learning_rate=learning_rate)\n",
    "    aggregator = FedAvgAggregator()\n",
    "    \n",
    "    round_accuracies = []\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        client_models = []\n",
    "        for train_loader in non_iid_train_loaders:\n",
    "            client_model = FraudDetectionModel(input_dim).to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            \n",
    "            trainer.model = client_model\n",
    "            trainer.train_one_round(train_loader, epochs=local_epochs)\n",
    "            \n",
    "            client_models.append(client_model)\n",
    "        \n",
    "        aggregator.aggregate(client_models, global_model)\n",
    "        \n",
    "        # Evaluate\n",
    "        accs = []\n",
    "        for test_loader in non_iid_test_loaders:\n",
    "            metrics = evaluator.evaluate(global_model, test_loader, label=f'Non-IID (IID%={iid_degree*100}) Round {round_num+1}')\n",
    "            accs.append(metrics['accuracy'])\n",
    "        \n",
    "        avg_acc = np.mean(accs)\n",
    "        round_accuracies.append(avg_acc)\n",
    "        print(f'  Round {round_num + 1}: Avg Accuracy = {avg_acc:.4f}')\n",
    "    \n",
    "    heterogeneity_results[f'IID%={iid_degree*100}'] = round_accuracies\n",
    "\n",
    "print(f'\\n‚úÖ Heterogeneity simulation complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8c578",
   "metadata": {},
   "source": [
    "## Step 10: Client Dropout Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425235a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n{\"=\"*60}')\n",
    "print('üîå CLIENT DROPOUT SIMULATION')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "dropout_rates = [0.0, 0.2, 0.4]\n",
    "dropout_results = {}\n",
    "\n",
    "for dropout_rate in dropout_rates:\n",
    "    print(f'\\nüöÄ Training with Dropout Rate = {dropout_rate*100}%')\n",
    "    \n",
    "    global_model = FraudDetectionModel(input_dim).to(device)\n",
    "    trainer = ClientTrainer(model=None, device=device, learning_rate=learning_rate)\n",
    "    aggregator = FedAvgAggregator()\n",
    "    \n",
    "    round_accuracies = []\n",
    "    \n",
    "    for round_num in range(num_rounds):\n",
    "        # Simulate client dropout\n",
    "        active_clients = preprocessor.simulate_client_dropout(\n",
    "            len(client_train_loaders),\n",
    "            dropout_rate=dropout_rate,\n",
    "            seed=round_num\n",
    "        )\n",
    "        \n",
    "        num_active = np.sum(active_clients)\n",
    "        print(f'  Round {round_num + 1}: {num_active}/{len(active_clients)} clients active')\n",
    "        \n",
    "        client_models = []\n",
    "        active_train_loaders = [loader for loader, active in zip(client_train_loaders, active_clients) if active]\n",
    "        \n",
    "        for train_loader in active_train_loaders:\n",
    "            client_model = FraudDetectionModel(input_dim).to(device)\n",
    "            client_model.load_state_dict(global_model.state_dict())\n",
    "            \n",
    "            trainer.model = client_model\n",
    "            trainer.train_one_round(train_loader, epochs=local_epochs)\n",
    "            \n",
    "            client_models.append(client_model)\n",
    "        \n",
    "        aggregator.aggregate(client_models, global_model)\n",
    "        \n",
    "        # Evaluate on all test clients\n",
    "        accs = []\n",
    "        for test_loader in client_test_loaders:\n",
    "            metrics = evaluator.evaluate(global_model, test_loader, label=f'Dropout={dropout_rate*100}% Round {round_num+1}')\n",
    "            accs.append(metrics['accuracy'])\n",
    "        \n",
    "        avg_acc = np.mean(accs)\n",
    "        round_accuracies.append(avg_acc)\n",
    "        print(f'    Avg Accuracy = {avg_acc:.4f}')\n",
    "    \n",
    "    dropout_results[f'Dropout {dropout_rate*100}%'] = round_accuracies\n",
    "\n",
    "print(f'\\n‚úÖ Dropout simulation complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8572fb13",
   "metadata": {},
   "source": [
    "## Step 11: Heterogeneity and Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7eedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heterogeneity and dropout effects\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: IID vs Non-IID\n",
    "for label, accs in heterogeneity_results.items():\n",
    "    axes[0].plot(range(1, num_rounds + 1), accs, marker='o', label=label, linewidth=2)\n",
    "axes[0].set_xlabel('Round', fontsize=11)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[0].set_title('Effect of Data Heterogeneity (Non-IID)', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Client Dropout\n",
    "for label, accs in dropout_results.items():\n",
    "    axes[1].plot(range(1, num_rounds + 1), accs, marker='s', label=label, linewidth=2)\n",
    "axes[1].set_xlabel('Round', fontsize=11)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[1].set_title('Effect of Client Dropout', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('‚úÖ Heterogeneity and robustness plots generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e9ce5",
   "metadata": {},
   "source": [
    "## Step 12: Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a41efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n{\"=\"*70}')\n",
    "print('üìà COMPREHENSIVE FEDERATED LEARNING ANALYSIS SUMMARY')\n",
    "print(f'{\"=\"*70}')\n",
    "\n",
    "print('\\n1Ô∏è‚É£ ALGORITHM COMPARISON (FedAvg vs FedProx vs FedDANE):')\n",
    "print('-' * 70)\n",
    "for alg_name, result in results.items():\n",
    "    final_acc = np.mean(result['final_accuracies'])\n",
    "    print(f'  {alg_name}: Final Accuracy = {final_acc:.4f}')\n",
    "\n",
    "print('\\n2Ô∏è‚É£ PRIVACY-UTILITY TRADE-OFF:')\n",
    "print('-' * 70)\n",
    "for dp_name, result in dp_results.items():\n",
    "    final_acc = result['accuracies'][-1]\n",
    "    final_eps = result['privacy_budgets'][-1][0]\n",
    "    print(f'  {dp_name}: Accuracy={final_acc:.4f}, Œµ={final_eps:.4f}')\n",
    "\n",
    "print('\\n3Ô∏è‚É£ ROBUSTNESS TO DATA HETEROGENEITY:')\n",
    "print('-' * 70)\n",
    "for label, accs in heterogeneity_results.items():\n",
    "    print(f'  {label}: Final Accuracy = {accs[-1]:.4f}')\n",
    "\n",
    "print('\\n4Ô∏è‚É£ ROBUSTNESS TO CLIENT DROPOUT:')\n",
    "print('-' * 70)\n",
    "for label, accs in dropout_results.items():\n",
    "    print(f'  {label}: Final Accuracy = {accs[-1]:.4f}')\n",
    "\n",
    "print(f'\\n{\"=\"*70}')\n",
    "print('‚úÖ Analysis Complete!')\n",
    "print(f'{\"=\"*70}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
